# ===== Core =====
APP_PORT=8080
DATABASE_URL=postgresql+psycopg2://emaide:emaide@db:5432/emaide
TZ=America/Toronto
ENVIRONMENT=local   # local, dev, staging, production

# ===== Teams (Default) =====
DEFAULT_ORG_NAME=demo-org
DEFAULT_TEAM_NAME=demo-team

# ===== GitHub =====
GITHUB_API_BASE_URL=https://api.github.com
GITHUB_TOKEN=REPLACE_ME   # optional for public repos, recommended to avoid rate limits
GITHUB_OWNER=desktop
GITHUB_REPO=desktop

# ===== Jira Cloud (optional) =====
JIRA_BASE_URL=https://your-site.atlassian.net
JIRA_EMAIL=you@example.com
JIRA_API_TOKEN=REPLACE_ME
JIRA_PROJECT_KEY=DEMO
JIRA_BOARD_ID=REPLACE_ME   # numeric, optional for now

# ===== Remote LLM (OpenAI-compatible) =====
LLM_MODE=openai
COMPOSE_PROFILES=
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=REPLACE_ME
LLM_MODEL=gpt-4.1-mini
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=2000
LLM_TIMEOUT_SECONDS=60

# ===== Remote LLM (Ollama) =====
# Uncomment below block to use Remote Ollama LLM
# LLM_MODE=ollama
# COMPOSE_PROFILES=
# OLLAMA_BASE_URL=https://ollama.com/
# LLM_API_KEY=REPLACE_ME
# OLLAMA_MODEL=gpt-oss:120b
# LLM_TEMPERATURE=0.2
# LLM_MAX_TOKENS=4000
# LLM_TIMEOUT_SECONDS=60

# ===== local LLM (Ollama) =====
# Uncomment below block to use local LLM via Ollama
# LLM_MODE=local
# COMPOSE_PROFILES=local_llm
# OLLAMA_BASE_URL=http://ollama:11434
# LLM_API_KEY=
# OLLAMA_MODEL=qwen2.5:3b
# LLM_TEMPERATURE=0.2
# LLM_MAX_TOKENS=4000
# LLM_TIMEOUT_SECONDS=300

# ===== Scheduling (worker) =====
SYNC_INTERVAL_MINUTES=60
METRICS_DAILY_HOUR=2
METRICS_DAILY_MINUTE=0
